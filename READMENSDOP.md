# Задание 16: Face Recognition с Siamese Network 
 
## Задача: создать Siamese Network для распознавания лиц. 
 
## Требования: 
- Siamese архитектура с общими весами 
- Triplet loss для метрического обучения 
- Вычисление similarity между лицами 
- Верификация и идентификация
## Что нужно дополнить: 
-  1. Backbone архитектуру 
-  2. Contrastive loss 
-  3. Triplet loss 
-  4. Train step 
-  5. Функции verify и identify
-  6. Data augmentation для создания пар
# Алгоритм и архитектура работы НС по блокам
Основная идея алгоритма заключается в создании "цифрового отпечатка" лица — компактного векторного представления (эмбеддинга), который сохраняет уникальные черты человека, но отбрасывает несущественные детали вроде освещения, ракурса или выражения лица.
В отличие от классических классификаторов, эта система не учится распознавать конкретных людей, а учится понимать, какие лица похожи, а какие — нет. Это позволяет системе работать с людьми, которых она никогда не видела в процессе обучения.

- БЛОК 1: ИНИЦИАЛИЗАЦИЯ И ПОДГОТОВКА СИСТЕМЫ
Первым шагом является создание и настройка всех компонентов системы. Создается Siamese (сиамская) нейронная сеть — особая архитектура, где два или более идентичных подсети (с одинаковыми весами) работают параллельно. 
Одновременно инициализируется менеджер обучения, который будет контролировать процесс настройки параметров сети, и генератор данных, отвечающий за подготовку учебных примеров. 
Генератор загружает все доступные изображения лиц в оперативную память, группируя их по принадлежности к конкретным людям. 

- БЛОК 2: ФОРМИРОВАНИЕ ОБУЧАЮЩИХ ПРИМЕРОВ
Сердцем системы обучения является концепция "триплетов" — специально сформированных троек изображений. Каждый триплет состоит из трех фотографий: якорного изображения '(anchor)', позитивного примера '(positive)' и негативного примера '(negative)'.
Якорное и позитивное изображения принадлежат одному и тому же человеку, но это разные фотографии — возможно, сделанные в разное время, при разном освещении, с разным выражением лица.Генератор данных случайным образом формирует тысячи таких троек, 
обеспечивая разнообразие обучающих примеров.
Перед подачей в нейронную сеть изображения проходят процедуру аугментации — искусственного разнообразия данных. 
Аугментация учит сеть быть устойчивой к естественным вариациям в фотографиях и предотвращает запоминание конкретных изображений вместо выучивания общих признаков.

- БЛОК 3: ПРОЦЕСС ОБУЧЕНИЯ НЕЙРОННОЙ СЕТИ
Обучение происходит по принципу контрастного обучения. На каждом шаге сеть получает батч триплетов и должна решить сложную задачу: научиться размещать эмбеддинги лиц в многомерном пространстве так, чтобы фотографии одного человека оказывались близко друг к другу,
а фотографии разных людей — далеко.
Технически это реализуется через специальную функцию потерь 'Triplet Loss'. Эта функция математически выражает простое требование: расстояние между якорным и позитивным изображениями должно быть меньше, чем расстояние между якорным и негативным изображениями,
как минимум на заданную величину (маржу).
Процесс повторяется итеративно: сеть обрабатывает триплеты, вычисляет потери, определяет, в каком направлении нужно изменить свои веса, чтобы уменьшить ошибку, и совершает эти изменения.
Со временем сеть учится извлекать из изображений именно те признаки, которые отличают одного человека от другого — форму и расположение ключевых элементов лица, уникальные черты, которые сохраняются на разных фотографиях одного человека, но различаются у разных людей.

- БЛОК 4: СОЗДАНИЕ ВЕКТОРНЫХ ПРЕДСТАВЛЕНИЙ ЛИЦ
После обучения система готова к основной работе — преобразованию изображений лиц в векторные представления. Этот процесс начинается с предварительной обработки фотографии: приведения к стандартному размеру, нормализации цветовых значений. 
Сначала сверточные слои обнаруживают базовые визуальные паттерны — края, текстуры, простые формы. Последующие слои комбинируют эти паттерны в более сложные структуры — части лица, а затем и целостные лицевые признаки.
Финальный слой производит компактный вектор из 128 чисел — цифровой отпечаток лица.
Ключевой этап — нормализация этого вектора. Все векторы приводятся к единичной длине, что позволяет использовать косинусное расстояние как меру сходства.

- БЛОК 5: СИСТЕМА ВЕРИФИКАЦИИ — СРАВНЕНИЕ ДВУХ ЛИЦ
Верификация решает задачу подтверждения идентичности: "Принадлежат ли два изображения одному человеку?" Это бинарная задача сравнения один-к-одному.
Алгоритм извлекает векторные представления обоих изображений и вычисляет расстояние между ними в многомерном пространстве. Если векторы соответствуют одному человеку, они будут расположены близко друг к другу, и расстояние окажется небольшим.
Если же это фотографии разных людей, их векторы будут разнесены, и расстояние будет значительным.
Решение принимается на основе сравнения вычисленного расстояния с пороговым значением. Низкий порог делает систему более строгой: она реже ошибочно принимает разных людей за одного, но чаще ошибочно отвергает одного и того же человека на разных фотографиях.
Высокий порог делает систему более либеральной, с обратным соотношением ошибок.

- БЛОК 6: СИСТЕМА ИДЕНТИФИКАЦИИ — ПОИСК В БАЗЕ ДАННЫХ
Идентификация решает более сложную задачу поиска: "Кто этот человек?" Это задача сравнения один-ко-многим, требующая поиска по базе данных известных лиц.
Алгоритм начинает с извлечения вектора из тестового изображения. Затем он последовательно вычисляет расстояния между этим вектором и всеми векторами в базе данных. 
После нахождения наиболее близкого соответствия система сравнивает полученное расстояние с порогом идентификации. Если расстояние меньше порога, система возвращает имя человека из базы данных. Если же минимальное расстояние превышает порог, система заключает, что этот человек не известен ей, и возвращает статус "Неизвестный".
Важная особенность — идентификация всегда выполняется относительно конкретной базы данных. Система не "узнает" человека в абсолютном смысле, а лишь находит наиболее похожего человека среди тех, чьи лица были заранее зарегистрированы.

- БЛОК 7: РЕГИСТРАЦИЯ НОВЫХ ЛИЦ И УПРАВЛЕНИЕ БАЗОЙ
Для добавления нового человека в систему выполняется процедура регистрации. Сначала система проверяет качество предоставленного изображения: наличие четко видимого лица, достаточное освещение, отсутствие сильных искажений. Затем извлекается векторное представление.
Перед добавлением выполняется проверка на дубликаты: система ищет наиболее похожее лицо в существующей базе. Если найденное сходство превышает определенный уровень, система предлагает проверить, не пытаются ли зарегистрировать уже существующего человека под другим именем.
Это предотвращает дублирование записей и поддерживает целостность базы данных.
При успешной проверке вектор добавляется в базу вместе с присвоенным именем. База может периодически переиндексироваться для оптимизации скорости поиска. В производственных системах часто реализуются механизмы версионирования базы, контроля доступа и ведения журнала изменений.

- БЛОК 8: ОЦЕНКА КАЧЕСТВА И МОНИТОРИНГ РАБОТЫ
Качество системы распознавания лиц оценивается по нескольким взаимодополняющим метрикам. Точность идентификации измеряет успешность поиска в базе данных.
Более тонкие метрики включают 'False Accept Rate (FAR)' — вероятность принять разных людей за одного, и 'False Reject Rate (FRR)' — вероятность отвергнуть одного и того же человека. Кривая зависимости FAR от FRR при изменении порога позволяет найти оптимальный баланс для конкретного применения системы. 
Мониторинг в реальном времени включает отслеживание времени обработки, загрузки системы, частоты различных типов ошибок. Для критически важных применений могут реализовываться механизмы автоматической перекалибровки и адаптации к изменяющимся условиям.

# 3. Ответ на контрольный вопрос
## В чём разница между KNN и K-Means? Когда использовать каждый? 
KNN (K-ближайших соседей) и K-Means (K-средних) — это два фундаментальных, но принципиально разных алгоритма машинного обучения, которые часто путают из-за схожих названий и использования параметра K. Их ключевое различие лежит в типе решаемых задач: KNN — это алгоритм контролируемого обучения для классификации или регрессии, а K-Means — алгоритм неконтролируемого обучения для кластеризации.

KNN работает по принципу "расскажи мне, кто твои соседи, и я скажу, кто ты". Это "ленивый" алгоритм, который не строит модель на этапе обучения, а просто запоминает все размеченные данные. Когда поступает новый объект для классификации, KNN находит K ближайших к нему соседей из обучающей выборки (например, по евклидову расстоянию) и относит объект к тому классу, который преобладает среди этих соседей. Таким образом, KNN отвечает на вопрос: "К какому известному классу принадлежит этот новый объект?" Его используют, когда у вас уже есть исторические данные с готовыми метками (например, архив писем с пометками "спам"/"не спам") и нужно предсказать категорию для новых наблюдений. Типичные применения — рекомендательные системы, медицинская диагностика или распознавание образов.

Напротив, K-Means решает задачу поиска скрытой структуры в данных. У него нет заранее известных ответов. Алгоритм самостоятельно пытается разделить все данные на K компактных групп (кластеров) так, чтобы объекты внутри одного кластера были максимально похожи, а объекты разных кластеров — максимально различны. Он итеративно назначает точки ближайшим центроидам (условным центрам кластеров) и пересчитывает положение этих центроидов. K-Means отвечает на вопрос: "На какие естественные группы можно разбить мои данные?" Его применяют для сегментации клиентов, анализа рынка, сжатия изображений или любого исследовательского анализа, где категории изначально не определены. Например, маркетолог может использовать K-Means, чтобы обнаружить в базе клиентов несколько типичных поведенческих профилей.

Таким образом, выбор между ними определяется исходной постановкой задачи. Используйте KNN, когда у вас есть примеры с правильными ответами и нужно эти ответы предсказывать для новых данных. Используйте K-Means, когда ответов нет, и ваша цель — исследовать данные и обнаружить в них внутренние закономерности и группировки. Проще говоря, KNN нужен для предсказания известных меток, а K-Means — для открытия новых, ранее неизвестных категорий
